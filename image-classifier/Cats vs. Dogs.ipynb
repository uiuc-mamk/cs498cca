{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can a Computer Recognize Cats vs. Dogs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>This is an introduction to Image Classification, one application of AI. We explore Image Classification through using a simple, interactive model previously trained to differentiate between the US's most popular pets - cats and dogs. This notebook has been adapted from previous work by <a href=\"https://towardsdatascience.com/image-classifier-cats-vs-dogs-with-convolutional-neural-networks-cnns-and-google-colabs-4e9af21ae7a8\">Greg Surma</a> and <a href=\"https://medium.com/@parthvadhadiya424/hello-world-program-in-keras-with-cnn-dog-vs-cat-classification-efc6f0da3cc5\">Parth Vadhadiya</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/header.png\" style=\"width: 75%; height: auto; border-radius: 4px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can our computers tell the difference between a cat and a dog? In this notebook, we're going to explore the application of Artificial Intelligence known as <b>Image Classification</b>. In Image Classification, we assign a label to an image from a fixed set of categories. In this case, we'd pass our computers an image and it will respond with a prediction of either cat or dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do humans see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before we get into how exactly we intend to train a computer to recognize cats and dogs, let's think for a second on how we as humans recognize objects. Getting a machine to analyze a visual image is rooted in how we see the world surrounding us.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/visualPathway.png\" style=\"width: 25%; height:auto; border-radius: 4px;\">\n",
    "<p style=\"width: 100%; text-align: center;\"><i>Eyes send signals to the brain for processing.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When we look at an object, the light receptors in our eyes send signals to our brain. Our brain processes these signals and makes sense of what our eyes are seeing.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Our brains analyze images in layers of increasing detail. First, we might distinguish a basic outline of what we're looking at. At higher levels, our brain does more sophisticated processing, eventually recognizing that a certain combination of edges and colors may translate into a cat, or a dog.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do computers see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Computers will break images into tiny little squares called <b>pixels</b>. Each pixel is represented by 3 color values: Red, Green, and Blue. A computer will \"see\" an image purely as the ordered sequence of these <b>color values</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/RGBLayers.png\" style=\"border-radius: 4px;\">\n",
    "<p style=\"width: 100%; text-align: center;\"><i>Computers see separate Red, Green, and Blue layers when analyzing an image.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So, we know a computer sees a sequence of pixel values, but how does it make sense of what it's seeing? As humans, our brain does the processing for us. With computers, we have to explicitly program that processing ability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Deep Learning Models</b> are a type of machine learning algorithm that is well suited for spotting patterns. A class of deep learning models that works well for analyzing images is known as a <b>Convolutional Neural Network</b> or CNN. CNN's can be used to: <ul><li>Classify images (name what they see)</li>\n",
    "    <li>Group images by similarity</li>\n",
    "    <li>Recognize objects within an image</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through CNN processing, the computer is able to recognize more complex attributes of an image, with the eventual goal of determining what the image contains. CNN's are the basis of how we'll be able to programmatically differentiate between cats and dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Our Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to train a computer by showing it enough labeled images of cats and dogs, a task known as <b>supervised learning</b>. The more cats a computer sees, the better it will become at detecting cats, and likewise with dogs. The computer will recognize patterns specific to identifying either animal.<br/><br/>Eventually, when given a new, unlabeled image of a cat or dog, the computer will be able to recognize which animal is in the image with a certain degree of confidence.<br/><br/>In this manner, training was done on a machine using the <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\">Dogs vs. Cats dataset</a> and a special model file was produced. Think of the model as rules for a computer to follow based on the patterns identified for cats and dogs.<br/>\n",
    "\n",
    "We're now going to take you through the steps to use this model file in building your own image classifier application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to get the functionality we need, we'll have to link the following Python libraries into our code.\n",
    "<ul>\n",
    "    <li><b>Keras</b>: this neural network library runs on top of Tensorflow and allows us to load and use our trained model to classify images.</li>\n",
    "    <li><b>OpenCV</b>: this library of functions that support computer vision lets our program read in an image for classification.</li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json # Keras library\n",
    "import cv2                               # OpenCV library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we need to generate a model from a pretrained model file, <b>model.json</b>. Think of the model file as having the directions the program will use to build its actual model. The model can be thought of as the rules the program uses to determine whether an image contains a cat or a dog.\n",
    "\n",
    "So, we need to tell our program to open this model file, read its contents and then use these contents along with a few more instructions to build the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ashleytoney/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')                # Open model file\n",
    "loaded_model_json = json_file.read()               # Read in the contents of the model file\n",
    "json_file.close()                                  # Close the model file\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)  # Instantiate the model\n",
    "loaded_model.load_weights(\"model.h5\")              # Load weights\n",
    "loaded_model.compile(optimizer = 'adam',           # Build the model\n",
    "                     loss = 'binary_crossentropy', \n",
    "                     metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the Image Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have we have successfully built our model file, we are ready to start predicting whether a certain image contains a cat or a dog. We first read in an image and format it for processing. The image is then passed to the model, which returns the number 0 if the image is most likely a cat or 1, if it's most likely a dog. Congratulations, you now have a working image classifer! Let's look at the results from our sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/sample1.png --> prediction: cat\n",
      "images/sample2.png --> prediction: cat\n",
      "images/sample3.png --> prediction: cat\n",
      "images/sample4.png --> prediction: dog\n",
      "images/sample5.png --> prediction: dog\n",
      "images/sample6.png --> prediction: dog\n",
      "images/sample7.png --> prediction: dog\n"
     ]
    }
   ],
   "source": [
    "def predict_cat_or_dog(img_path):\n",
    "    img = cv2.imread(img_path)       # Read in the image\n",
    "    img = cv2.resize(img, (50,50))   # Format the image for processing\n",
    "    img = img.reshape(1, 50, 50, 3)\n",
    "\n",
    "    if loaded_model.predict(img) == 0: # Send the image to the model and interpret the result\n",
    "        print(img_path + \" --> prediction: cat\")\n",
    "    else:\n",
    "        print(img_path + \" --> prediction: dog\")\n",
    "\n",
    "predict_cat_or_dog(\"images/sample1.png\") # Interpret sample image 1\n",
    "predict_cat_or_dog(\"images/sample2.png\") # Interpret sample image 2\n",
    "predict_cat_or_dog(\"images/sample3.png\") # Interpret sample image 3\n",
    "predict_cat_or_dog(\"images/sample4.png\") # Interpret sample image 4\n",
    "predict_cat_or_dog(\"images/sample5.png\") # Interpret sample image 5\n",
    "predict_cat_or_dog(\"images/sample6.png\") # Interpret sample image 6\n",
    "predict_cat_or_dog(\"images/sample7.png\") # Interpret sample image 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th style=\"text-align:center;\">Image 1</th>\n",
    "            <th style=\"text-align:center;\">Image 2</th>\n",
    "            <th style=\"text-align:center;\">Image 3</th>\n",
    "            <th style=\"text-align:center;\">Image 4</th>\n",
    "            <th style=\"text-align:center;\">Image 5</th>\n",
    "            <th style=\"text-align:center;\">Image 6</th>\n",
    "            <th style=\"text-align:center;\">Image 7</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center;\">images/sample1.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample2.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample3.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample4.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample5.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample6.png</td>\n",
    "            <td style=\"text-align:center;\">images/sample7.png</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample1.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample2.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample3.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample4.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample5.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample6.png\" /></td>\n",
    "            <td style=\"text-align:center;\"><img src=\"images/sample7.png\" /></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tried passing all of our sample images above, you might have noticed something interesting. The last file \"sample7.png\" was predicted as a dog, when clearly to us humans, it's a cat! Granted, the cat is in an unusual pose by not directly facing the camera. This is a good time to point out that these predictions are only as good as the dataset. Meaning, if we developed an entirely new model by training the computer with a different set of images, this outcome may have been different - or perhaps if we trained with twice as many images. We might have improved our result by introducing more cats into our training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Promising Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've learned some of the underlying concepts of how computers see through interacting with an Image Classifier. These concepts have many more applications far beyond what we've just explored. Imagine a machine being able to more accurately asses a tissue sample than a pathologist, or a security camera that could detect a threat almost instantaneously. AI has the potential to revolutionize the fields of medicine, surveillance, agriculture, transportation and so much more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
