{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can a Computer Recognize Cats vs. Dogs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>This is an introduction to Image Classification, one application of AI. We explore Image Classification through using a simple, interactive model previously trained to differentiate between the US's most popular pets - cats and dogs. This notebook has been adapted from previous work by <a href=\"https://towardsdatascience.com/image-classifier-cats-vs-dogs-with-convolutional-neural-networks-cnns-and-google-colabs-4e9af21ae7a8\">Greg Surma</a> and <a href=\"https://medium.com/@parthvadhadiya424/hello-world-program-in-keras-with-cnn-dog-vs-cat-classification-efc6f0da3cc5\">Parth Vadhadiya</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/header.png\" style=\"width: 75%; height: auto; border-radius: 4px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can our computers tell the difference between a cat and a dog? In this notebook, we're going to explore the application of Artificial Intelligence known as <b>Image Classification</b>. In Image Classification, we assign a label to an image from a fixed set of categories. In this case, we'd pass our computers an image and it will respond with a prediction of either cat or dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do humans see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before we get into how exactly we intend to train a computer to recognize cats and dogs, let's think for a second on how we as humans recognize objects. Getting a machine to analyze a visual image is rooted in how we see the world surrounding us.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/visualPathway.png\" style=\"width: 25%; height:auto; border-radius: 4px;\">\n",
    "<p style=\"width: 100%; text-align: center;\"><i>Eyes send signals to the brain for processing.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When we look at an object, the light receptors in our eyes send signals to our brain. Our brain processes these signals and makes sense of what our eyes are seeing.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Our brains analyze images in layers of increasing detail. First, we might distinguish a basic outline of what we're looking at. At higher levels, our brain does more sophisticated processing, eventually recognizing that a certain combination of edges and colors may translate into a cat, or a dog.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do computers see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Computers will break images into tiny little squares called <b>pixels</b>. Each pixel is represented by 3 color values: Red, Green, and Blue. A computer will \"see\" an image purely as the ordered sequence of these <b>color values</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_diagrams/RGBLayers.png\" style=\"border-radius: 4px;\">\n",
    "<p style=\"width: 100%; text-align: center;\"><i>Computers see separate Red, Green, and Blue layers when analyzing an image.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So, we know a computer sees a sequence of pixel values, but how does it make sense of what it's seeing? As humans, our brain does the processing for us. With computers, we have to explicitly program that processing ability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Deep Learning Models</b> are a type of machine learning algorithm that is well suited for spotting patterns. A class of deep learning models that works well for analyzing images is known as a <b>Convolutional Neural Network</b> or CNN. CNN's can be used to: <ul><li>Classify images (name what they see)</li>\n",
    "    <li>Group images by similarity</li>\n",
    "    <li>Recognize objects within an image</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through CNN processing, the computer is able to recognize more complex attributes of an image, with the eventual goal of determining what the image contains. CNN's are the basis of how we'll be able to programmatically differentiate between cats and dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Our Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to train a computer by showing it enough labeled images of cats and dogs, a task known as <b>supervised learning</b>. The more cats a computer sees, the better it will become at detecting cats, and likewise with dogs. The computer will recognize patterns specific to identifying either animal.<br/><br/>Eventually, when given a new, unlabeled image of a cat or dog, the computer will be able to recognize which animal is in the image with a certain degree of confidence.<br/><br/>In this manner, training was done on a machine using the <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\">Dogs vs. Cats dataset</a> and a special model file was produced. Think of the model as rules for a computer to follow based on the patterns identified for cats and dogs.<br/>\n",
    "\n",
    "Using our provided sample images, or even some of your own, feel free to interact with our model to see if the computer's predictions match your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0c3cb6c8a94e21bacec1ffdbbab5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='file', options=('sample1.png', 'sample2.png', 'sample3.png', 'sampâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "@interact\n",
    "def show_images(file=sorted(os.listdir('images/'))):\n",
    "    display(Image('images/' + file))\n",
    "\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    #print(\"Loaded model from disk\")\n",
    "\n",
    "    loaded_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    img = cv2.imread(\"images/\" + file)\n",
    "    img = cv2.resize(img, (50,50))\n",
    "    img = img.reshape(1, 50, 50, 3)\n",
    "\n",
    "    if loaded_model.predict(img) == 0:\n",
    "        print(\"prediction: cat\")\n",
    "    else:\n",
    "        print(\"prediction: dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tried passing all of our sample images above, you might have noticed something interesting. The last file \"sample7.png\" was predicted as a dog, when clearly to us humans, it's a cat! Granted, the cat is in an unusual pose by not directly facing the camera. This is a good time to point out that these predictions are only as good as the dataset. Meaning, if we developed an entirely new model by training the computer with a different set of images, this outcome may have been different. We might have improved our result by introducing more side-posing cats into our training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Promising Future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've learned some of the underlying concepts of how computers see through interacting with an Image Classifier. These concepts have many more applications far beyond what we've just explored. Imagine a machine being able to more accurately asses a tissue sample than a pathologist, or a security camera that could detect a threat almost instantaneously. AI has the potential to revolutionize the fields of medicine, surveillance, agriculture, transportation and so much more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
